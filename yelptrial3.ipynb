{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/nsinha280/lstm-on-Yelp-review-data/blob/master/lstm-final.ipynb"
      ],
      "metadata": {
        "id": "IXlyMbgfUS-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zKw0hkDyUU2f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBgj0q-0xgOR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from nltk.stem import PorterStemmer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews=pd.read_csv('yelp.csv')\n",
        "df_reviews=df_reviews[['text', 'stars']]\n",
        "df_reviews.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uOQBu3iVxlf5",
        "outputId": "ddad6d81-b6d1-421f-db83-090a5d9b1ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  stars\n",
              "0  My wife took me here on my birthday for breakf...      5\n",
              "1  I have no idea why some people give bad review...      5\n",
              "2  love the gyro plate. Rice is so good and I als...      4\n",
              "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5\n",
              "4  General Manager Scott Petello is a good egg!!!...      5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7485aabc-fd18-4e8b-8e99-7f10ce0bd3de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My wife took me here on my birthday for breakf...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have no idea why some people give bad review...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7485aabc-fd18-4e8b-8e99-7f10ce0bd3de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7485aabc-fd18-4e8b-8e99-7f10ce0bd3de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7485aabc-fd18-4e8b-8e99-7f10ce0bd3de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('mode.chained_assignment', None)\n",
        "df_reviews[\"labels\"] = df_reviews[\"stars\"].apply(lambda x: -1 if x < 3  else (1 if x > 3 else 0))\n",
        "df_reviews = df_reviews.drop(\"stars\",axis=1)\n",
        "\n",
        "df_reviews"
      ],
      "metadata": {
        "id": "_XJur3xLxsWx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "8044aad9-4c91-41fa-e8f8-551a162d864c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  labels\n",
              "0     My wife took me here on my birthday for breakf...       1\n",
              "1     I have no idea why some people give bad review...       1\n",
              "2     love the gyro plate. Rice is so good and I als...       1\n",
              "3     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...       1\n",
              "4     General Manager Scott Petello is a good egg!!!...       1\n",
              "...                                                 ...     ...\n",
              "9995  First visit...Had lunch here today - used my G...       0\n",
              "9996  Should be called house of deliciousness!\\n\\nI ...       1\n",
              "9997  I recently visited Olive and Ivy for business ...       1\n",
              "9998  My nephew just moved to Scottsdale recently so...      -1\n",
              "9999  4-5 locations.. all 4.5 star average.. I think...       1\n",
              "\n",
              "[10000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef1b6cad-3e39-4413-a383-04b41923c039\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My wife took me here on my birthday for breakf...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have no idea why some people give bad review...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>First visit...Had lunch here today - used my G...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>I recently visited Olive and Ivy for business ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef1b6cad-3e39-4413-a383-04b41923c039')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef1b6cad-3e39-4413-a383-04b41923c039 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef1b6cad-3e39-4413-a383-04b41923c039');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_df(df_reviews):\n",
        "    n_rows = len(df_reviews)\n",
        "    ind = np.random.permutation(n_rows)\n",
        "    df_reviews = df_reviews.iloc[ind,:]\n",
        "    df_train = df_reviews.iloc[:int(0.8*n_rows),:]\n",
        "    df_val = df_reviews.iloc[int(0.8*n_rows):int(0.9*n_rows),:]\n",
        "    df_test = df_reviews.iloc[int(0.9*n_rows):,:]\n",
        "\n",
        "    return df_train, df_val, df_test"
      ],
      "metadata": {
        "id": "fMn8XwDRyOcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_rows = len(df_reviews)\n",
        "dfs_train, dfs_val, dfs_test = [],[],[]\n",
        "gb = df_reviews.groupby('labels')\n",
        "for x in gb.groups:\n",
        "    group = gb.get_group(x)\n",
        "    df_train, df_val, df_test = split_df(group)\n",
        "    dfs_train.append(df_train)\n",
        "    dfs_val.append(df_val)\n",
        "    dfs_test.append(df_test)\n",
        "df_train = pd.concat(dfs_train, ignore_index=True)\n",
        "ind = np.random.permutation(len(df_train))\n",
        "df_train = df_train.iloc[ind,:]\n",
        "df_val = pd.concat(dfs_val, ignore_index=True)\n",
        "ind = np.random.permutation(len(df_val))\n",
        "df_val = df_val.iloc[ind,:]\n",
        "df_test = pd.concat(dfs_test, ignore_index=True)\n",
        "ind = np.random.permutation(len(df_test))\n",
        "df_test = df_test.iloc[ind,:]\n",
        "print(f'Number of training examples: {len(df_train)}')\n",
        "print(f'Number of validation examples: {len(df_val)}')\n",
        "print(f'Number of test examples: {len(df_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gTEFIpCyZjB",
        "outputId": "0bed1d99-1437-4c4e-9338-bec118721138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 7998\n",
            "Number of validation examples: 1000\n",
            "Number of test examples: 1002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(18,4))\n",
        "titles = ['Train set','Test set','Val set']\n",
        "for i,dataf in enumerate([df_train,df_test,df_val]):\n",
        "    ax = fig.add_subplot(1,3,i+1)\n",
        "    Y, labels = pd.factorize(dataf['labels'])\n",
        "    ax.bar(labels, height=pd.Series(Y).value_counts())\n",
        "    ax.set_xticks(ticks=range(len(labels)))\n",
        "    ax.set_xticklabels(labels,fontsize=10)\n",
        "    ax.set_xlabel('Review')\n",
        "    ax.set_ylabel('Number of examples')\n",
        "    ax.set_title(titles[i])\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XxAOo-KybVvn",
        "outputId": "9af782d5-23d4-42a9-8e54-567688336cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install hydra-core\n",
        "%pip install omegaconf\n",
        "%pip install sentencepiece\n",
        "%pip install transformers\n",
        "%pip install bitarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sOZbqPevyvhx",
        "outputId": "66eb635a-1aab-4cc4-a874-8ff7371f343d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.3.1-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting omegaconf<2.4,>=2.2\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core) (5.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from hydra-core) (23.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core) (3.12.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=1264b839c9223700c32b4dd3677bdfb06ccbaa00977edd2b779f30c0555cb129\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.1 omegaconf-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.8/dist-packages (2.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from omegaconf) (6.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.8/dist-packages (from omegaconf) (4.9.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.4/240.4 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitarray\n",
            "Successfully installed bitarray-2.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from statistics import mean\n",
        "import pickle\n",
        "from transformers import XLMRobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.optim import SGD"
      ],
      "metadata": {
        "id": "SNo2qWPJyyNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI_FWaXwb0rD",
        "outputId": "1d8b9461-0df1-4985-c45a-c794b48d8671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (4.9.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2022.6.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (1.21.6)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.7.0 sacrebleu-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xlmr = torch.hub.load('pytorch/fairseq', 'xlmr.base', force_reload=True)\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsBhMrwXy1Wh",
        "outputId": "9f5d2dc6-5abe-4d46-9f24-ec9e19e52b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/fairseq/zipball/main\" to /root/.cache/torch/hub/main.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running build_ext\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cythoning fairseq/data/data_utils_fast.pyx to fairseq/data/data_utils_fast.cpp\n",
            "cythoning fairseq/data/token_block_utils_fast.pyx to fairseq/data/token_block_utils_fast.cpp\n",
            "building 'fairseq.libbleu' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.8\n",
            "creating build/temp.linux-x86_64-3.8/fairseq\n",
            "creating build/temp.linux-x86_64-3.8/fairseq/clib\n",
            "creating build/temp.linux-x86_64-3.8/fairseq/clib/libbleu\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.8 -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-3.8/fairseq/clib/libbleu/libbleu.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.8 -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-3.8/fairseq/clib/libbleu/module.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "creating build/lib.linux-x86_64-3.8\n",
            "creating build/lib.linux-x86_64-3.8/fairseq\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-3.8/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.8/fairseq/libbleu.cpython-38-x86_64-linux-gnu.so\n",
            "building 'fairseq.data.data_utils_fast' extension\n",
            "creating build/temp.linux-x86_64-3.8/fairseq/data\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/include/python3.8 -c fairseq/data/data_utils_fast.cpp -o build/temp.linux-x86_64-3.8/fairseq/data/data_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/fairseq/data/data_utils_fast.o -o build/lib.linux-x86_64-3.8/fairseq/data/data_utils_fast.cpython-38-x86_64-linux-gnu.so\n",
            "building 'fairseq.data.token_block_utils_fast' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/include/python3.8 -c fairseq/data/token_block_utils_fast.cpp -o build/temp.linux-x86_64-3.8/fairseq/data/token_block_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/fairseq/data/token_block_utils_fast.o -o build/lib.linux-x86_64-3.8/fairseq/data/token_block_utils_fast.cpython-38-x86_64-linux-gnu.so\n",
            "building 'fairseq.libbase' extension\n",
            "creating build/temp.linux-x86_64-3.8/fairseq/clib/libbase\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c fairseq/clib/libbase/balanced_assignment.cpp -o build/temp.linux-x86_64-3.8/fairseq/clib/libbase/balanced_assignment.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbase -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/fairseq/clib/libbase/balanced_assignment.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/fairseq/libbase.cpython-38-x86_64-linux-gnu.so\n",
            "building 'fairseq.libnat' extension\n",
            "creating build/temp.linux-x86_64-3.8/fairseq/clib/libnat\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c fairseq/clib/libnat/edit_dist.cpp -o build/temp.linux-x86_64-3.8/fairseq/clib/libnat/edit_dist.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/fairseq/clib/libnat/edit_dist.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/fairseq/libnat.cpython-38-x86_64-linux-gnu.so\n",
            "building 'alignment_train_cpu_binding' extension\n",
            "creating build/temp.linux-x86_64-3.8/examples\n",
            "creating build/temp.linux-x86_64-3.8/examples/operators\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c examples/operators/alignment_train_cpu.cpp -o build/temp.linux-x86_64-3.8/examples/operators/alignment_train_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=alignment_train_cpu_binding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/examples/operators/alignment_train_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/alignment_train_cpu_binding.cpython-38-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libbleu.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/data/data_utils_fast.cpython-38-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/data/token_block_utils_fast.cpython-38-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libbase.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libnat.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/alignment_train_cpu_binding.cpython-38-x86_64-linux-gnu.so -> \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d35d2f16124b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxlmr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch/fairseq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xlmr.base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXLMRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlm-roberta-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m                                            verbose=verbose, skip_validation=skip_validation)\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhubconf_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/roberta/model_xlmr.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name_or_path, checkpoint_file, data_name_or_path, bpe, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     ):\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhub_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         x = hub_utils.from_pretrained(\n",
            "\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdb\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_generation_constraints\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/scoring/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m _build_scorer, register_scorer, SCORER_REGISTRY, _ = registry.setup_registry(\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;34m\"--scoring\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bleu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m )\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for errors check: https://github.com/facebookresearch/fairseq/issues/1070\n"
      ],
      "metadata": {
        "id": "RyrNkOSj1_uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.data.processors.utils import InputExample\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm, tnrange\n",
        "import time"
      ],
      "metadata": {
        "id": "fBL3sWl0noz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=5)"
      ],
      "metadata": {
        "id": "E1rdLX2m2CaR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "863731ba-1c21-4244-c88f-ca9bf77c038f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-21fac4fa2f7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta-base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RobertaTokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install regex requests hydra-core omegaconf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1mOjux-pEwn",
        "outputId": "dd7e957b-33f9-48fd-ca49-e181f949b315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.25.1)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.8/dist-packages (1.3.1)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.8/dist-packages (2.3.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from hydra-core) (23.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core) (5.10.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.8/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from omegaconf) (6.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core) (3.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\n",
        "roberta.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rT95hHuApOQJ",
        "outputId": "4f853ab3-99b2-460b-ad38-ea466f69fe55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running build_ext\n",
            "cythoning fairseq/data/data_utils_fast.pyx to fairseq/data/data_utils_fast.cpp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cythoning fairseq/data/token_block_utils_fast.pyx to fairseq/data/token_block_utils_fast.cpp\n",
            "building 'fairseq.libbleu' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.8\n",
            "creating build/temp.linux-x86_64-3.8/fairseq\n",
            "creating build/temp.linux-x86_64-3.8/fairseq/clib\n",
            "creating build/temp.linux-x86_64-3.8/fairseq/clib/libbleu\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.8 -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-3.8/fairseq/clib/libbleu/libbleu.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.8 -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-3.8/fairseq/clib/libbleu/module.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "creating build/lib.linux-x86_64-3.8\n",
            "creating build/lib.linux-x86_64-3.8/fairseq\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-3.8/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.8/fairseq/libbleu.cpython-38-x86_64-linux-gnu.so\n",
            "building 'fairseq.data.data_utils_fast' extension\n",
            "creating build/temp.linux-x86_64-3.8/fairseq/data\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/include/python3.8 -c fairseq/data/data_utils_fast.cpp -o build/temp.linux-x86_64-3.8/fairseq/data/data_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/fairseq/data/data_utils_fast.o -o build/lib.linux-x86_64-3.8/fairseq/data/data_utils_fast.cpython-38-x86_64-linux-gnu.so\n",
            "building 'fairseq.data.token_block_utils_fast' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/include/python3.8 -c fairseq/data/token_block_utils_fast.cpp -o build/temp.linux-x86_64-3.8/fairseq/data/token_block_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/fairseq/data/token_block_utils_fast.o -o build/lib.linux-x86_64-3.8/fairseq/data/token_block_utils_fast.cpython-38-x86_64-linux-gnu.so\n",
            "building 'fairseq.libbase' extension\n",
            "creating build/temp.linux-x86_64-3.8/fairseq/clib/libbase\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c fairseq/clib/libbase/balanced_assignment.cpp -o build/temp.linux-x86_64-3.8/fairseq/clib/libbase/balanced_assignment.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbase -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/fairseq/clib/libbase/balanced_assignment.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/fairseq/libbase.cpython-38-x86_64-linux-gnu.so\n",
            "building 'fairseq.libnat' extension\n",
            "creating build/temp.linux-x86_64-3.8/fairseq/clib/libnat\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c fairseq/clib/libnat/edit_dist.cpp -o build/temp.linux-x86_64-3.8/fairseq/clib/libnat/edit_dist.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/fairseq/clib/libnat/edit_dist.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/fairseq/libnat.cpython-38-x86_64-linux-gnu.so\n",
            "building 'alignment_train_cpu_binding' extension\n",
            "creating build/temp.linux-x86_64-3.8/examples\n",
            "creating build/temp.linux-x86_64-3.8/examples/operators\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c examples/operators/alignment_train_cpu.cpp -o build/temp.linux-x86_64-3.8/examples/operators/alignment_train_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=alignment_train_cpu_binding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/examples/operators/alignment_train_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/alignment_train_cpu_binding.cpython-38-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libbleu.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/data/data_utils_fast.cpython-38-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/data/token_block_utils_fast.cpython-38-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libbase.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libnat.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/alignment_train_cpu_binding.cpython-38-x86_64-linux-gnu.so -> \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d77f2be136a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mroberta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch/fairseq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roberta.large'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mroberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m                                            verbose=verbose, skip_validation=skip_validation)\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhubconf_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/roberta/model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name_or_path, checkpoint_file, data_name_or_path, bpe, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     ):\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhub_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         x = hub_utils.from_pretrained(\n",
            "\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdb\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_generation_constraints\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/scoring/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m _build_scorer, register_scorer, SCORER_REGISTRY, _ = registry.setup_registry(\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;34m\"--scoring\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bleu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m )\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    }
  ]
}